{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#원본 행렬 R생성, 분해 행렬 P와 Q 초기화, 잠재 요인 차원 K는 3으로 설정\n",
    "\n",
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN],\n",
    "             [np.NaN, 5, np.NaN, 3, 1],\n",
    "             [np.NaN, np.NaN, 3, 4, 4],\n",
    "             [5, 2, 1, 2, np.NaN]])\n",
    "\n",
    "num_users, num_items = R.shape\n",
    "K=3\n",
    "\n",
    "#P와 Q행렬의 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력합니다.\n",
    "\n",
    "np.random.seed(1)\n",
    "P = np.random.normal(scale = 1./K, size = (num_users, K))\n",
    "Q = np.random.normal(scale = 1./K, size = (num_items, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    #두 개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "    \n",
    "    #실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출해 실제 R행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step : 0 rmse: 3.2356492299762243\n",
      "### iteration step : 0 rmse: 3.2347528001574153\n",
      "### iteration step : 0 rmse: 3.227890683722564\n",
      "### iteration step : 0 rmse: 3.226019021038736\n",
      "### iteration step : 0 rmse: 3.226216290884265\n",
      "### iteration step : 0 rmse: 3.224888661494888\n",
      "### iteration step : 0 rmse: 3.2229733576446744\n",
      "### iteration step : 0 rmse: 3.221160317013953\n",
      "### iteration step : 0 rmse: 3.216003133977435\n",
      "### iteration step : 0 rmse: 3.214226625144921\n",
      "### iteration step : 0 rmse: 3.2143239254643983\n",
      "### iteration step : 0 rmse: 3.212966188648189\n",
      "### iteration step : 50 rmse: 0.48876048154916224\n",
      "### iteration step : 50 rmse: 0.4884723987391722\n",
      "### iteration step : 50 rmse: 0.4876207150071948\n",
      "### iteration step : 50 rmse: 0.4874637190185317\n",
      "### iteration step : 50 rmse: 0.48756020594296495\n",
      "### iteration step : 50 rmse: 0.4869015293119821\n",
      "### iteration step : 50 rmse: 0.48699439754833906\n",
      "### iteration step : 50 rmse: 0.486501682630296\n",
      "### iteration step : 50 rmse: 0.478928554588659\n",
      "### iteration step : 50 rmse: 0.47805135125275705\n",
      "### iteration step : 50 rmse: 0.47762440377620946\n",
      "### iteration step : 50 rmse: 0.47651567945401757\n",
      "### iteration step : 100 rmse: 0.16763303854364986\n",
      "### iteration step : 100 rmse: 0.16740341242058143\n",
      "### iteration step : 100 rmse: 0.16736502411119952\n",
      "### iteration step : 100 rmse: 0.1669366918961561\n",
      "### iteration step : 100 rmse: 0.16695583277801768\n",
      "### iteration step : 100 rmse: 0.1669138765865151\n",
      "### iteration step : 100 rmse: 0.16649563322111577\n",
      "### iteration step : 100 rmse: 0.1665428028952482\n",
      "### iteration step : 100 rmse: 0.16586570829865654\n",
      "### iteration step : 100 rmse: 0.16577565049163792\n",
      "### iteration step : 100 rmse: 0.165511025877661\n",
      "### iteration step : 100 rmse: 0.16499028119651263\n",
      "### iteration step : 150 rmse: 0.08395412029206697\n",
      "### iteration step : 150 rmse: 0.08396066758364708\n",
      "### iteration step : 150 rmse: 0.08395789540583423\n",
      "### iteration step : 150 rmse: 0.08368090217049921\n",
      "### iteration step : 150 rmse: 0.08371792530260695\n",
      "### iteration step : 150 rmse: 0.0837485508509587\n",
      "### iteration step : 150 rmse: 0.08342649567862329\n",
      "### iteration step : 150 rmse: 0.08346773946981081\n",
      "### iteration step : 150 rmse: 0.0831188194625774\n",
      "### iteration step : 150 rmse: 0.08312985592714754\n",
      "### iteration step : 150 rmse: 0.08312081005890387\n",
      "### iteration step : 150 rmse: 0.08297934935982143\n",
      "### iteration step : 200 rmse: 0.05024821463491267\n",
      "### iteration step : 200 rmse: 0.05032702747049818\n",
      "### iteration step : 200 rmse: 0.05031991750448867\n",
      "### iteration step : 200 rmse: 0.05009873652331798\n",
      "### iteration step : 200 rmse: 0.05014989215912894\n",
      "### iteration step : 200 rmse: 0.050205122733710604\n",
      "### iteration step : 200 rmse: 0.04993243330744377\n",
      "### iteration step : 200 rmse: 0.049955646850622475\n",
      "### iteration step : 200 rmse: 0.049688994989825166\n",
      "### iteration step : 200 rmse: 0.04970954314072735\n",
      "### iteration step : 200 rmse: 0.04971368814249516\n",
      "### iteration step : 200 rmse: 0.04981152747959079\n",
      "### iteration step : 250 rmse: 0.034285608591289284\n",
      "### iteration step : 250 rmse: 0.03438752947462731\n",
      "### iteration step : 250 rmse: 0.03436182817771204\n",
      "### iteration step : 250 rmse: 0.03417516809627896\n",
      "### iteration step : 250 rmse: 0.034241575107678904\n",
      "### iteration step : 250 rmse: 0.03430301785745041\n",
      "### iteration step : 250 rmse: 0.03405393823032021\n",
      "### iteration step : 250 rmse: 0.034061120065062525\n",
      "### iteration step : 250 rmse: 0.033808736723232514\n",
      "### iteration step : 250 rmse: 0.03384224616138761\n",
      "### iteration step : 250 rmse: 0.033842843732742565\n",
      "### iteration step : 250 rmse: 0.03406168427301695\n",
      "### iteration step : 300 rmse: 0.026156432064317427\n",
      "### iteration step : 300 rmse: 0.026263892118507222\n",
      "### iteration step : 300 rmse: 0.026213327118175322\n",
      "### iteration step : 300 rmse: 0.02605283650461279\n",
      "### iteration step : 300 rmse: 0.026133730983856938\n",
      "### iteration step : 300 rmse: 0.026191478930993765\n",
      "### iteration step : 300 rmse: 0.0259577934382201\n",
      "### iteration step : 300 rmse: 0.02595392763035456\n",
      "### iteration step : 300 rmse: 0.025689522592092413\n",
      "### iteration step : 300 rmse: 0.025742932293860127\n",
      "### iteration step : 300 rmse: 0.02575647309452138\n",
      "### iteration step : 300 rmse: 0.026030807515972976\n",
      "### iteration step : 350 rmse: 0.021981353878717746\n",
      "### iteration step : 350 rmse: 0.022087663195431873\n",
      "### iteration step : 350 rmse: 0.022013303325704742\n",
      "### iteration step : 350 rmse: 0.021874363531877303\n",
      "### iteration step : 350 rmse: 0.02196650113742373\n",
      "### iteration step : 350 rmse: 0.022015446475350576\n",
      "### iteration step : 350 rmse: 0.0217951093972657\n",
      "### iteration step : 350 rmse: 0.021784480141368055\n",
      "### iteration step : 350 rmse: 0.021502497383703818\n",
      "### iteration step : 350 rmse: 0.02157613317608634\n",
      "### iteration step : 350 rmse: 0.021608758258417533\n",
      "### iteration step : 350 rmse: 0.02190295271007446\n",
      "### iteration step : 400 rmse: 0.01984133181718988\n",
      "### iteration step : 400 rmse: 0.019944423555593564\n",
      "### iteration step : 400 rmse: 0.019851573701311843\n",
      "### iteration step : 400 rmse: 0.01972975385666349\n",
      "### iteration step : 400 rmse: 0.01982919130551469\n",
      "### iteration step : 400 rmse: 0.019868544099134817\n",
      "### iteration step : 400 rmse: 0.019659953694384995\n",
      "### iteration step : 400 rmse: 0.019645567711478684\n",
      "### iteration step : 400 rmse: 0.019349665219207352\n",
      "### iteration step : 400 rmse: 0.019439305886111896\n",
      "### iteration step : 400 rmse: 0.019488479641226696\n",
      "### iteration step : 400 rmse: 0.019784857029427786\n",
      "### iteration step : 450 rmse: 0.01872278005509543\n",
      "### iteration step : 450 rmse: 0.018822709281756896\n",
      "### iteration step : 450 rmse: 0.018717068913714597\n",
      "### iteration step : 450 rmse: 0.018607906140960372\n",
      "### iteration step : 450 rmse: 0.018711634634432955\n",
      "### iteration step : 450 rmse: 0.018743026199517097\n",
      "### iteration step : 450 rmse: 0.018543688301062854\n",
      "### iteration step : 450 rmse: 0.018527326166159937\n",
      "### iteration step : 450 rmse: 0.01822254401671759\n",
      "### iteration step : 450 rmse: 0.018323271389809322\n",
      "### iteration step : 450 rmse: 0.01838418277095034\n",
      "### iteration step : 450 rmse: 0.01867611938240585\n",
      "### iteration step : 500 rmse: 0.01811085934933135\n",
      "### iteration step : 500 rmse: 0.01820835373618068\n",
      "### iteration step : 500 rmse: 0.018094249413347255\n",
      "### iteration step : 500 rmse: 0.017994002889331215\n",
      "### iteration step : 500 rmse: 0.01810021206890641\n",
      "### iteration step : 500 rmse: 0.01812581609830147\n",
      "### iteration step : 500 rmse: 0.01793308350783159\n",
      "### iteration step : 500 rmse: 0.017915672617582333\n",
      "### iteration step : 500 rmse: 0.017605648976644538\n",
      "### iteration step : 500 rmse: 0.01771367286708975\n",
      "### iteration step : 500 rmse: 0.01778228969352362\n",
      "### iteration step : 500 rmse: 0.018068534780930436\n",
      "### iteration step : 550 rmse: 0.017753779338978305\n",
      "### iteration step : 550 rmse: 0.01784956005013934\n",
      "### iteration step : 550 rmse: 0.01772984186429235\n",
      "### iteration step : 550 rmse: 0.017635789229609556\n",
      "### iteration step : 550 rmse: 0.017743497412842292\n",
      "### iteration step : 550 rmse: 0.017765151377443278\n",
      "### iteration step : 550 rmse: 0.01757686548902747\n",
      "### iteration step : 550 rmse: 0.01755885450721712\n",
      "### iteration step : 550 rmse: 0.017245752844815363\n",
      "### iteration step : 550 rmse: 0.01735857547671308\n",
      "### iteration step : 550 rmse: 0.01743216964439219\n",
      "### iteration step : 550 rmse: 0.017713369359170818\n",
      "### iteration step : 600 rmse: 0.01752890920665457\n",
      "### iteration step : 600 rmse: 0.01762349769194491\n",
      "### iteration step : 600 rmse: 0.01749994088994726\n",
      "### iteration step : 600 rmse: 0.017410253458912613\n",
      "### iteration step : 600 rmse: 0.017518943141862267\n",
      "### iteration step : 600 rmse: 0.017537965868904822\n",
      "### iteration step : 600 rmse: 0.017352599697940046\n",
      "### iteration step : 600 rmse: 0.017334197189417793\n",
      "### iteration step : 600 rmse: 0.01701922157219172\n",
      "### iteration step : 600 rmse: 0.017135292389729058\n",
      "### iteration step : 600 rmse: 0.017212153787635548\n",
      "### iteration step : 600 rmse: 0.01748932432884371\n",
      "### iteration step : 650 rmse: 0.017375179464125715\n",
      "### iteration step : 650 rmse: 0.017468902959709678\n",
      "### iteration step : 650 rmse: 0.017342593585726474\n",
      "### iteration step : 650 rmse: 0.0172560928146163\n",
      "### iteration step : 650 rmse: 0.017365488539504603\n",
      "### iteration step : 650 rmse: 0.017382758431909985\n",
      "### iteration step : 650 rmse: 0.017199312949841027\n",
      "### iteration step : 650 rmse: 0.017180612692662994\n",
      "### iteration step : 650 rmse: 0.016864422369674968\n",
      "### iteration step : 650 rmse: 0.01698279645431457\n",
      "### iteration step : 650 rmse: 0.017061879305331155\n",
      "### iteration step : 650 rmse: 0.01733590476074775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step : 700 rmse: 0.017261120760306947\n",
      "### iteration step : 700 rmse: 0.017354167493944143\n",
      "### iteration step : 700 rmse: 0.017225769182736696\n",
      "### iteration step : 700 rmse: 0.017141710322301103\n",
      "### iteration step : 700 rmse: 0.01725166154047401\n",
      "### iteration step : 700 rmse: 0.017267742690743913\n",
      "### iteration step : 700 rmse: 0.0170855932026094\n",
      "### iteration step : 700 rmse: 0.017066635166619007\n",
      "### iteration step : 700 rmse: 0.016749592213894778\n",
      "### iteration step : 700 rmse: 0.016869694162313622\n",
      "### iteration step : 700 rmse: 0.01695036144242414\n",
      "### iteration step : 700 rmse: 0.01722189589559208\n",
      "### iteration step : 750 rmse: 0.01716993293709818\n",
      "### iteration step : 750 rmse: 0.017262404398667087\n",
      "### iteration step : 750 rmse: 0.017132325614296003\n",
      "### iteration step : 750 rmse: 0.01705024129279326\n",
      "### iteration step : 750 rmse: 0.01716066288905664\n",
      "### iteration step : 750 rmse: 0.017175911456832657\n",
      "### iteration step : 750 rmse: 0.016994677926677932\n",
      "### iteration step : 750 rmse: 0.016975477302657218\n",
      "### iteration step : 750 rmse: 0.016657783110841512\n",
      "### iteration step : 750 rmse: 0.01677925979951706\n",
      "### iteration step : 750 rmse: 0.016861121419182928\n",
      "### iteration step : 750 rmse: 0.017130616966090865\n",
      "### iteration step : 800 rmse: 0.01709236287382665\n",
      "### iteration step : 800 rmse: 0.017184311318470587\n",
      "### iteration step : 800 rmse: 0.01705280682376513\n",
      "### iteration step : 800 rmse: 0.01697240321547106\n",
      "### iteration step : 800 rmse: 0.01708324513947594\n",
      "### iteration step : 800 rmse: 0.01709788491114339\n",
      "### iteration step : 800 rmse: 0.016917339840869093\n",
      "### iteration step : 800 rmse: 0.016897900839245052\n",
      "### iteration step : 800 rmse: 0.016579670151448855\n",
      "### iteration step : 800 rmse: 0.016702301864397952\n",
      "### iteration step : 800 rmse: 0.016785116343011296\n",
      "### iteration step : 800 rmse: 0.017052875447053372\n",
      "### iteration step : 850 rmse: 0.017023181736045404\n",
      "### iteration step : 850 rmse: 0.017114634076504123\n",
      "### iteration step : 850 rmse: 0.016981865927679227\n",
      "### iteration step : 850 rmse: 0.016902956567226585\n",
      "### iteration step : 850 rmse: 0.0170141879881357\n",
      "### iteration step : 850 rmse: 0.017028360263877655\n",
      "### iteration step : 850 rmse: 0.016848368256935576\n",
      "### iteration step : 850 rmse: 0.016828690659096143\n",
      "### iteration step : 850 rmse: 0.016509991870354086\n",
      "### iteration step : 850 rmse: 0.016633639097354564\n",
      "### iteration step : 850 rmse: 0.016717254487184897\n",
      "### iteration step : 850 rmse: 0.01698347616694114\n",
      "### iteration step : 900 rmse: 0.016959372288213127\n",
      "### iteration step : 900 rmse: 0.017050344210761792\n",
      "### iteration step : 900 rmse: 0.016916418386181763\n",
      "### iteration step : 900 rmse: 0.016838882831393\n",
      "### iteration step : 900 rmse: 0.016950483666282903\n",
      "### iteration step : 900 rmse: 0.016964279004760295\n",
      "### iteration step : 900 rmse: 0.016784758838706892\n",
      "### iteration step : 900 rmse: 0.01676484105864168\n",
      "### iteration step : 900 rmse: 0.016445718247499193\n",
      "### iteration step : 900 rmse: 0.016570289837486357\n",
      "### iteration step : 900 rmse: 0.01665460827212202\n",
      "### iteration step : 900 rmse: 0.016919422295966872\n",
      "### iteration step : 950 rmse: 0.01689916221944295\n",
      "### iteration step : 950 rmse: 0.01698966596842336\n",
      "### iteration step : 950 rmse: 0.016854654405253133\n",
      "### iteration step : 950 rmse: 0.01677841268630279\n",
      "### iteration step : 950 rmse: 0.01689036897296015\n",
      "### iteration step : 950 rmse: 0.0169038469770396\n",
      "### iteration step : 950 rmse: 0.016724748490546438\n",
      "### iteration step : 950 rmse: 0.016704588937647837\n",
      "### iteration step : 950 rmse: 0.016385073876516935\n",
      "### iteration step : 950 rmse: 0.01651050792932073\n",
      "### iteration step : 950 rmse: 0.016595464311081415\n",
      "### iteration step : 950 rmse: 0.01685895481234329\n"
     ]
    }
   ],
   "source": [
    "#R >0인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장\n",
    "non_zeros = [ (i, j, R[i, j]) for i in range(num_users) for j in range(num_items) if R[i, j] > 0 ]\n",
    "\n",
    "steps = 1000\n",
    "learning_rate = 0.01\n",
    "r_lambda = 0.01\n",
    "\n",
    "# SGD 기법으로 P와 Q 매트릭스를 계속 업데이트\n",
    "for step in range(steps):\n",
    "    for i, j, r in non_zeros :\n",
    "        #실제 값과 예측 값의 차이인 오류 값 구함\n",
    "        eij = r - np.dot(P[i, :], Q[j, : ].T)\n",
    "        # Regularization을 반영한 SGD 업데이트 공식 적용\n",
    "        P[i, :] = P[i, :] + learning_rate*(eij * Q[j, :] - r_lambda* P[i, :])\n",
    "        Q[j, :] = Q[j, :] + learning_rate*(eij * P[i, :] - r_lambda* Q[j, :])\n",
    "        rmse = get_rmse(R, P, Q, non_zeros)\n",
    "        if (step % 50) == 0 :\n",
    "            print(\"### iteration step :\" , step, \"rmse:\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_matrix = np.dot(P, Q.T)\n",
    "print('예측 행렬 :\\n', np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testAI",
   "language": "python",
   "name": "testai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
